{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46951df6",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Team: BofaBros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c77e10af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import string\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, GRU\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras_tuner as kt\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5137d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove automatic formatting with symbol usage (Ex: $ sign -> MathJax)\n",
    "pd.options.display.html.use_mathjax=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2089d38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "1  The Swedish buyout firm has sold its remaining...   neutral\n",
       "2    $SPY wouldn't be surprised to see a green close  positive\n",
       "3  Shell's $70 Billion BG Deal Meets Shareholder ...  negative\n",
       "4  SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...  negative"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read training data\n",
    "train_data = pd.read_csv('../data/advanced_trainset.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0f0296d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earnings per share ( EPS ) dropped to EUR 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$SONC Amazing run since middle of March - obvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruukki Romania , the local arm of Finnish meta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Self-service and automation are in a bigger ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alma Media 's operating profit amounted to EUR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence\n",
       "0  Earnings per share ( EPS ) dropped to EUR 0.21...\n",
       "1  $SONC Amazing run since middle of March - obvi...\n",
       "2  Ruukki Romania , the local arm of Finnish meta...\n",
       "3  Self-service and automation are in a bigger ro...\n",
       "4  Alma Media 's operating profit amounted to EUR..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read testing data\n",
    "test_data = pd.read_csv('../data/advanced_testset.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29b76a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Last Sale</th>\n",
       "      <th>Net Change</th>\n",
       "      <th>% Change</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Country</th>\n",
       "      <th>IPO Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies Inc. Common Stock</td>\n",
       "      <td>$134.87</td>\n",
       "      <td>-1.0600</td>\n",
       "      <td>-0.78%</td>\n",
       "      <td>4.047629e+10</td>\n",
       "      <td>United States</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2070939</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>Electrical Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation Common Stock</td>\n",
       "      <td>$84.15</td>\n",
       "      <td>-1.9500</td>\n",
       "      <td>-2.265%</td>\n",
       "      <td>1.551901e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4585478</td>\n",
       "      <td>Basic Industries</td>\n",
       "      <td>Metal Fabrications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAC</td>\n",
       "      <td>Ares Acquisition Corporation Class A Ordinary ...</td>\n",
       "      <td>$9.83</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.204%</td>\n",
       "      <td>1.228750e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>186747</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Business Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACG</td>\n",
       "      <td>ATA Creativity Global American Depositary Shares</td>\n",
       "      <td>$1.21</td>\n",
       "      <td>-0.0600</td>\n",
       "      <td>-4.724%</td>\n",
       "      <td>3.796607e+07</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7154</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Service to the Health Industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AACI</td>\n",
       "      <td>Armada Acquisition Corp. I Common Stock</td>\n",
       "      <td>$9.9781</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>1.198%</td>\n",
       "      <td>2.066415e+08</td>\n",
       "      <td>United States</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>174251</td>\n",
       "      <td>Consumer Durables</td>\n",
       "      <td>Consumer Electronics/Appliances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                               Name Last Sale  \\\n",
       "0      A             Agilent Technologies Inc. Common Stock   $134.87   \n",
       "1     AA                    Alcoa Corporation Common Stock     $84.15   \n",
       "2    AAC  Ares Acquisition Corporation Class A Ordinary ...     $9.83   \n",
       "3   AACG   ATA Creativity Global American Depositary Shares     $1.21   \n",
       "4   AACI            Armada Acquisition Corp. I Common Stock   $9.9781   \n",
       "\n",
       "   Net Change % Change    Market Cap        Country  IPO Year   Volume  \\\n",
       "0     -1.0600   -0.78%  4.047629e+10  United States    1999.0  2070939   \n",
       "1     -1.9500  -2.265%  1.551901e+10            NaN    2016.0  4585478   \n",
       "2      0.0200   0.204%  1.228750e+09            NaN    2021.0   186747   \n",
       "3     -0.0600  -4.724%  3.796607e+07          China       NaN     7154   \n",
       "4      0.1181   1.198%  2.066415e+08  United States    2021.0   174251   \n",
       "\n",
       "              Sector                         Industry  \n",
       "0      Capital Goods              Electrical Products  \n",
       "1   Basic Industries               Metal Fabrications  \n",
       "2            Finance                Business Services  \n",
       "3      Miscellaneous   Service to the Health Industry  \n",
       "4  Consumer Durables  Consumer Electronics/Appliances  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read supplementary stock ticker data\n",
    "stocks = pd.read_csv('../data/stock_tickers.csv')\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f8ad1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set spacy NLP English pipeline\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814503fc",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Look through the dataset for things that catch your eye. What proportion of responses are negative, positive, and neutral? Do you see any imbalances in the data? What else do you find? Please provide charts and visualizations to support your claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e0c314e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Sentiment\n",
       "0   neutral       2363\n",
       "1  positive       1383\n",
       "2  negative        636"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_counts = train_data['Sentiment'].value_counts().to_frame().reset_index()\n",
    "sentiment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "196d8c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Sentiment=%{x}<br>Count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "neutral",
          "positive",
          "negative"
         ],
         "xaxis": "x",
         "y": [
          2363,
          1383,
          636
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Sentiment Counts in Training Data"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Sentiment"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"16a4eadd-19a3-484b-978b-533f088cd2e0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"16a4eadd-19a3-484b-978b-533f088cd2e0\")) {                    Plotly.newPlot(                        \"16a4eadd-19a3-484b-978b-533f088cd2e0\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Sentiment=%{x}<br>Count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"neutral\",\"positive\",\"negative\"],\"xaxis\":\"x\",\"y\":[2363,1383,636],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Sentiment\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Sentiment Counts in Training Data\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('16a4eadd-19a3-484b-978b-533f088cd2e0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.bar(sentiment_counts, x='index', y='Sentiment', \\\n",
    "             title=\"Sentiment Counts in Training Data\", labels={'index':'Sentiment', 'Sentiment': 'Count'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4ddfc",
   "metadata": {},
   "source": [
    "As we see from this bar chart, there is a significant imbalance in the number of observations we have for neutral, positive, and negative sentences. This will mean... TODO: HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e199828",
   "metadata": {},
   "source": [
    "## Subject of Sentences\n",
    "\n",
    "Another point of interest is to identify the subject of the sentence. This gives us an idea of what the sentiment is directed towards. For example, if the sentence is \"AAPL is popping off,\" we would want to identify the sentiment as well as what the sentiment is directed towards. This process is a combination of EDA and feature engineering, so we will include visualizations here and the actual data manipulation in the **Feature Engineering** section.\n",
    "\n",
    "TODO: talk about tokenization here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "aae3e464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"5e8ae6e945b6412b8b935e7e63480ae0-0\" class=\"displacy\" width=\"3375\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">According</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Finnish-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Russian</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Chamber</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Commerce ,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">all</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">major</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">construction</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">companies</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">Finland</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">operating</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">Russia .</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,2.0 2850.0,2.0 2850.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-1\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M205.0,441.5 L213.0,429.5 197.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-2\" stroke-width=\"2px\" d=\"M420,439.5 C420,177.0 915.0,177.0 915.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-4\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-5\" stroke-width=\"2px\" d=\"M245,439.5 C245,89.5 920.0,89.5 920.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,441.5 L928.0,429.5 912.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-6\" stroke-width=\"2px\" d=\"M945,439.5 C945,352.0 1080.0,352.0 1080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1080.0,441.5 L1088.0,429.5 1072.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-7\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1255.0,441.5 L1263.0,429.5 1247.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-8\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,89.5 2145.0,89.5 2145.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">predet</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,441.5 L1462,429.5 1478,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-9\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,177.0 2140.0,177.0 2140.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-10\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,264.5 2135.0,264.5 2135.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-11\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,352.0 2130.0,352.0 2130.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,441.5 L1987,429.5 2003,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-12\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,89.5 2845.0,89.5 2845.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2170,441.5 L2162,429.5 2178,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-13\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,352.0 2305.0,352.0 2305.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2305.0,441.5 L2313.0,429.5 2297.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-14\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,352.0 2480.0,352.0 2480.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2480.0,441.5 L2488.0,429.5 2472.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-15\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,352.0 2830.0,352.0 2830.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,441.5 L2687,429.5 2703,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-16\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,352.0 3005.0,352.0 3005.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3005.0,441.5 L3013.0,429.5 2997.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-17\" stroke-width=\"2px\" d=\"M3045,439.5 C3045,352.0 3180.0,352.0 3180.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5e8ae6e945b6412b8b935e7e63480ae0-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3180.0,441.5 L3188.0,429.5 3172.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = train_data.loc[0]['Sentence']\n",
    "doc=nlp(sent)\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7834f017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">According to the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Finnish\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "-Russian Chamber of Commerce , all the major construction companies of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Finland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " are operating in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Russia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21a207",
   "metadata": {},
   "source": [
    "With this visualization, we can see the breakdown of the sentence and determine the subjects as well as the relations between different words. However, as we can see in this example, the spacy NLP processing is not quite able to identify complex sentence tokens such as the \"Finnish-Russian Chamber of Commerce.\" Thus, we will have to select multiple groups to identify as subjects..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef982c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3520ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8ed0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1043363b",
   "metadata": {},
   "source": [
    "## Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f6eeae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Sentence series of negative sentiment into a string for EDA purposes\n",
    "neg_words = train_data[train_data['Sentiment'] == 'negative']['Sentence'].str.cat(sep=' ')\n",
    "neg_words = neg_words.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "810ee828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab as many words as possible while ignoring numbers, or incorrectly formatted words (preprocessing step)\n",
    "neg_words = [word.strip().lower() for word in neg_words if not any(c for c in word.strip() if c not in string.ascii_letters + \"'\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8e28d264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 524),\n",
       " ('in', 346),\n",
       " ('of', 314),\n",
       " ('to', 287),\n",
       " ('eur', 228),\n",
       " ('a', 185),\n",
       " ('mn', 164),\n",
       " ('from', 151),\n",
       " ('and', 149),\n",
       " ('for', 125)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(neg_words).most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2e1a6a",
   "metadata": {},
   "source": [
    "As we can see from the top 10 most common words in negative sentiment, it's impossible to gauge distinct or important words that correlate with negative sentiment. In order to find the more important words, we can calculate the term frequency - inverse data frequency score for each word and identify highest weighted words.\n",
    "\n",
    "TODO: discuss tf-idf formula and reasoning here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "9093ac7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "85aa0db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "6ea416ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words['Cleaned Sentence'] = important_words['Sentence'].apply(lambda x: ' '.join([''.join([char for char in word if char in string.ascii_letters + \"'\"]) for word in x.strip().lower().split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "dcaf1ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Cleaned Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>according to the finnishrussian chamber of com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>the swedish buyout firm has sold its remaining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "      <td>positive</td>\n",
       "      <td>spy wouldn't be surprised to see a green close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>shell's  billion bg deal meets shareholder ske...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ssh communications security corp stock exchang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>Investments in product development stood at 6....</td>\n",
       "      <td>neutral</td>\n",
       "      <td>investments in product development stood at  m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>HSBC Says Unit to Book $585 Million Charge on ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>hsbc says unit to book  million charge on sett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "      <td>rising costs have forced packaging producer hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>in the building and home improvement trade  sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>helsinki afx  kci konecranes said it has won a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4382 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment  \\\n",
       "0     According to the Finnish-Russian Chamber of Co...   neutral   \n",
       "1     The Swedish buyout firm has sold its remaining...   neutral   \n",
       "2       $SPY wouldn't be surprised to see a green close  positive   \n",
       "3     Shell's $70 Billion BG Deal Meets Shareholder ...  negative   \n",
       "4     SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...  negative   \n",
       "...                                                 ...       ...   \n",
       "4377  Investments in product development stood at 6....   neutral   \n",
       "4378  HSBC Says Unit to Book $585 Million Charge on ...  negative   \n",
       "4379  RISING costs have forced packaging producer Hu...  negative   \n",
       "4380  In the building and home improvement trade , s...   neutral   \n",
       "4381  HELSINKI AFX - KCI Konecranes said it has won ...  positive   \n",
       "\n",
       "                                       Cleaned Sentence  \n",
       "0     according to the finnishrussian chamber of com...  \n",
       "1     the swedish buyout firm has sold its remaining...  \n",
       "2        spy wouldn't be surprised to see a green close  \n",
       "3     shell's  billion bg deal meets shareholder ske...  \n",
       "4     ssh communications security corp stock exchang...  \n",
       "...                                                 ...  \n",
       "4377  investments in product development stood at  m...  \n",
       "4378  hsbc says unit to book  million charge on sett...  \n",
       "4379  rising costs have forced packaging producer hu...  \n",
       "4380  in the building and home improvement trade  sa...  \n",
       "4381  helsinki afx  kci konecranes said it has won a...  \n",
       "\n",
       "[4382 rows x 3 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "e5517cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, max_df=0.5,min_df=1, ngram_range=(1,3))\n",
    "vectors = vectorizer.fit_transform(important_words['Cleaned Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "5a15f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_tokens={i[1]:i[0] for i in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "07b8214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors = []  # all vectors by tfidf\n",
    "for row in vectors:\n",
    "    tfidf_vectors.append({dict_of_tokens[column]:value for (column,value) in zip(row.indices,row.data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "580a3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sorted_tfidfs =[]  # list of doc features each with tfidf weight\n",
    "#sort each dict of a document\n",
    "for dn in tfidf_vectors:\n",
    "    newD = sorted(dn.items(), key=lambda x: x[1], reverse=True)\n",
    "    newD = dict(newD)\n",
    "    doc_sorted_tfidfs.append(newD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "59d898eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_kw = [] # get the keyphrases as a list of names without tfidf values\n",
    "for doc_tfidf in doc_sorted_tfidfs:\n",
    "    ll = list(doc_tfidf.keys())\n",
    "    tfidf_kw.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "318dc03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(neg_words)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d04477",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_words = []\n",
    "for index in df.index:\n",
    "    doc = df.iloc[index].to_dict()\n",
    "    imp_words.append(dict(sorted(doc_0.items(), key=lambda item: item[1], reverse=True)).items[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "3456758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bg': 1.0,\n",
       " 'aaland': 0.0,\n",
       " 'ab': 0.0,\n",
       " 'aberdeen': 0.0,\n",
       " 'about': 0.0,\n",
       " 'above': 0.0,\n",
       " 'abp': 0.0,\n",
       " 'acanb': 0.0,\n",
       " 'acando': 0.0,\n",
       " 'accommodation': 0.0,\n",
       " 'according': 0.0,\n",
       " 'account': 0.0,\n",
       " 'accounting': 0.0,\n",
       " 'accused': 0.0,\n",
       " 'achieve': 0.0,\n",
       " 'acknowledged': 0.0,\n",
       " 'acquisition': 0.0,\n",
       " 'acting': 0.0,\n",
       " 'action': 0.0,\n",
       " 'activities': 0.0,\n",
       " 'activity': 0.0,\n",
       " 'actual': 0.0,\n",
       " 'actually': 0.0,\n",
       " 'added': 0.0,\n",
       " 'addition': 0.0,\n",
       " 'additional': 0.0,\n",
       " 'adds': 0.0,\n",
       " 'adjusted': 0.0,\n",
       " 'administration': 0.0,\n",
       " 'administrators': 0.0,\n",
       " 'adp': 0.0,\n",
       " 'adpnews': 0.0,\n",
       " 'adults': 0.0,\n",
       " 'advert': 0.0,\n",
       " 'advertising': 0.0,\n",
       " 'advice': 0.0,\n",
       " 'aero': 0.0,\n",
       " 'affect': 0.0,\n",
       " 'affected': 0.0,\n",
       " 'affecting': 0.0,\n",
       " 'affecto': 0.0,\n",
       " 'affectogenimap': 0.0,\n",
       " 'after': 0.0,\n",
       " 'afternoon': 0.0,\n",
       " 'ag': 0.0,\n",
       " 'again': 0.0,\n",
       " 'against': 0.0,\n",
       " 'agencies': 0.0,\n",
       " 'aggregate': 0.0,\n",
       " 'ago': 0.0,\n",
       " 'agree': 0.0,\n",
       " 'agreed': 0.0,\n",
       " 'agreement': 0.0,\n",
       " 'ahead': 0.0,\n",
       " 'aiming': 0.0,\n",
       " 'air': 0.0,\n",
       " 'airline': 0.0,\n",
       " 'airspace': 0.0,\n",
       " 'aker': 0.0,\n",
       " 'algeria': 0.0,\n",
       " 'alholma': 0.0,\n",
       " 'all': 0.0,\n",
       " 'alleged': 0.0,\n",
       " 'alliance': 0.0,\n",
       " 'allows': 0.0,\n",
       " 'almost': 0.0,\n",
       " 'alone': 0.0,\n",
       " 'along': 0.0,\n",
       " 'already': 0.0,\n",
       " 'also': 0.0,\n",
       " 'alternative': 0.0,\n",
       " 'am': 0.0,\n",
       " 'amazing': 0.0,\n",
       " 'america': 0.0,\n",
       " 'american': 0.0,\n",
       " 'amount': 0.0,\n",
       " 'amounted': 0.0,\n",
       " 'amounts': 0.0,\n",
       " 'amsterdam': 0.0,\n",
       " 'an': 0.0,\n",
       " 'analyst': 0.0,\n",
       " 'analysts': 0.0,\n",
       " 'and': 0.0,\n",
       " 'andy': 0.0,\n",
       " 'announced': 0.0,\n",
       " 'announcement': 0.0,\n",
       " 'annual': 0.0,\n",
       " 'another': 0.0,\n",
       " 'antti': 0.0,\n",
       " 'anything': 0.0,\n",
       " 'apart': 0.0,\n",
       " 'apparent': 0.0,\n",
       " 'apple': 0.0,\n",
       " 'applications': 0.0,\n",
       " 'apr': 0.0,\n",
       " 'april': 0.0,\n",
       " 'arcelormittal': 0.0,\n",
       " 'archipelago': 0.0,\n",
       " 'are': 0.0,\n",
       " 'area': 0.0,\n",
       " 'arm': 0.0,\n",
       " 'around': 0.0,\n",
       " 'arrangements': 0.0,\n",
       " 'as': 0.0,\n",
       " 'asda': 0.0,\n",
       " 'ashley': 0.0,\n",
       " 'asia': 0.0,\n",
       " 'asian': 0.0,\n",
       " 'asked': 0.0,\n",
       " 'asphalt': 0.0,\n",
       " 'aspocomp': 0.0,\n",
       " 'assets': 0.0,\n",
       " 'associated': 0.0,\n",
       " 'association': 0.0,\n",
       " 'asthma': 0.0,\n",
       " 'astrazeneca': 0.0,\n",
       " 'at': 0.0,\n",
       " 'atria': 0.0,\n",
       " 'attack': 0.0,\n",
       " 'attributes': 0.0,\n",
       " 'august': 0.0,\n",
       " 'automation': 0.0,\n",
       " 'autumn': 0.0,\n",
       " 'average': 0.0,\n",
       " 'aviva': 0.0,\n",
       " 'award': 0.0,\n",
       " 'awful': 0.0,\n",
       " 'axa': 0.0,\n",
       " 'axe': 0.0,\n",
       " 'axes': 0.0,\n",
       " 'babies': 0.0,\n",
       " 'back': 0.0,\n",
       " 'backdrop': 0.0,\n",
       " 'bad': 0.0,\n",
       " 'bae': 0.0,\n",
       " 'balance': 0.0,\n",
       " 'baltic': 0.0,\n",
       " 'ban': 0.0,\n",
       " 'bank': 0.0,\n",
       " 'banks': 0.0,\n",
       " 'barclays': 0.0,\n",
       " 'bargaining': 0.0,\n",
       " 'based': 0.0,\n",
       " 'basware': 0.0,\n",
       " 'bat': 0.0,\n",
       " 'baxalta': 0.0,\n",
       " 'bay': 0.0,\n",
       " 'be': 0.0,\n",
       " 'bear': 0.0,\n",
       " 'bearish': 0.0,\n",
       " 'beat': 0.0,\n",
       " 'beaten': 0.0,\n",
       " 'because': 0.0,\n",
       " 'become': 0.0,\n",
       " 'been': 0.0,\n",
       " 'beer': 0.0,\n",
       " 'before': 0.0,\n",
       " 'begin': 0.0,\n",
       " 'beginning': 0.0,\n",
       " 'being': 0.0,\n",
       " 'belarus': 0.0,\n",
       " 'believes': 0.0,\n",
       " 'bell': 0.0,\n",
       " 'below': 0.0,\n",
       " 'best': 0.0,\n",
       " 'beta': 0.0,\n",
       " 'bets': 0.0,\n",
       " 'between': 0.0,\n",
       " 'bhp': 0.0,\n",
       " 'bid': 0.0,\n",
       " 'big': 0.0,\n",
       " 'biggest': 0.0,\n",
       " 'billion': 0.0,\n",
       " 'billiton': 0.0,\n",
       " 'biobv': 0.0,\n",
       " 'biocare': 0.0,\n",
       " 'biohit': 0.0,\n",
       " 'bitter': 0.0,\n",
       " 'black': 0.0,\n",
       " 'blackberry': 0.0,\n",
       " 'blames': 0.0,\n",
       " 'blinkbox': 0.0,\n",
       " 'blip': 0.0,\n",
       " 'bln': 0.0,\n",
       " 'bn': 0.0,\n",
       " 'bns': 0.0,\n",
       " 'board': 0.0,\n",
       " 'boat': 0.0,\n",
       " 'boeing': 0.0,\n",
       " 'boerse': 0.0,\n",
       " 'bofa': 0.0,\n",
       " 'bond': 0.0,\n",
       " 'book': 0.0,\n",
       " 'booking': 0.0,\n",
       " 'books': 0.0,\n",
       " 'boost': 0.0,\n",
       " 'boss': 0.0,\n",
       " 'both': 0.0,\n",
       " 'bothnia': 0.0,\n",
       " 'bottled': 0.0,\n",
       " 'bottom': 0.0,\n",
       " 'bottoms': 0.0,\n",
       " 'boycotting': 0.0,\n",
       " 'bp': 0.0,\n",
       " 'brand': 0.0,\n",
       " 'branding': 0.0,\n",
       " 'brazil': 0.0,\n",
       " 'bread': 0.0,\n",
       " 'break': 0.0,\n",
       " 'breakdown': 0.0,\n",
       " 'breaking': 0.0,\n",
       " 'breakout': 0.0,\n",
       " 'breakup': 0.0,\n",
       " 'breweries': 0.0,\n",
       " 'brewery': 0.0,\n",
       " 'brewing': 0.0,\n",
       " 'brexit': 0.0,\n",
       " 'brick': 0.0,\n",
       " 'bricolage': 0.0,\n",
       " 'britain': 0.0,\n",
       " 'british': 0.0,\n",
       " 'broadband': 0.0,\n",
       " 'broader': 0.0,\n",
       " 'broker': 0.0,\n",
       " 'brother': 0.0,\n",
       " 'brought': 0.0,\n",
       " 'brydon': 0.0,\n",
       " 'budapest': 0.0,\n",
       " 'buffett': 0.0,\n",
       " 'building': 0.0,\n",
       " 'bulls': 0.0,\n",
       " 'bumping': 0.0,\n",
       " 'burdened': 0.0,\n",
       " 'burrill': 0.0,\n",
       " 'business': 0.0,\n",
       " 'but': 0.0,\n",
       " 'buy': 0.0,\n",
       " 'buyback': 0.0,\n",
       " 'by': 0.0,\n",
       " 'cabin': 0.0,\n",
       " 'calculates': 0.0,\n",
       " 'calling': 0.0,\n",
       " 'can': 0.0,\n",
       " 'canceled': 0.0,\n",
       " 'cancellation': 0.0,\n",
       " 'candle': 0.0,\n",
       " 'cap': 0.0,\n",
       " 'capacity': 0.0,\n",
       " 'capital': 0.0,\n",
       " 'capitals': 0.0,\n",
       " 'caps': 0.0,\n",
       " 'careful': 0.0,\n",
       " 'cargo': 0.0,\n",
       " 'cargotec': 0.0,\n",
       " 'carried': 0.0,\n",
       " 'carrier': 0.0,\n",
       " 'cars': 0.0,\n",
       " 'cartel': 0.0,\n",
       " 'case': 0.0,\n",
       " 'cash': 0.0,\n",
       " 'casinos': 0.0,\n",
       " 'cause': 0.0,\n",
       " 'caused': 0.0,\n",
       " 'cencorp': 0.0,\n",
       " 'cent': 0.0,\n",
       " 'central': 0.0,\n",
       " 'cents': 0.0,\n",
       " 'ceo': 0.0,\n",
       " 'certain': 0.0,\n",
       " 'cet': 0.0,\n",
       " 'chain': 0.0,\n",
       " 'chairman': 0.0,\n",
       " 'challenge': 0.0,\n",
       " 'challenges': 0.0,\n",
       " 'challenging': 0.0,\n",
       " 'change': 0.0,\n",
       " 'changed': 0.0,\n",
       " 'changes': 0.0,\n",
       " 'changing': 0.0,\n",
       " 'channel': 0.0,\n",
       " 'charge': 0.0,\n",
       " 'chargers': 0.0,\n",
       " 'chart': 0.0,\n",
       " 'chartered': 0.0,\n",
       " 'charts': 0.0,\n",
       " 'cheaper': 0.0,\n",
       " 'chief': 0.0,\n",
       " 'china': 0.0,\n",
       " 'chips': 0.0,\n",
       " 'christmas': 0.0,\n",
       " 'churning': 0.0,\n",
       " 'cinema': 0.0,\n",
       " 'cisco': 0.0,\n",
       " 'citigroup': 0.0,\n",
       " 'city': 0.0,\n",
       " 'claims': 0.0,\n",
       " 'cleaning': 0.0,\n",
       " 'cleared': 0.0,\n",
       " 'clearly': 0.0,\n",
       " 'clerical': 0.0,\n",
       " 'clockwork': 0.0,\n",
       " 'close': 0.0,\n",
       " 'closed': 0.0,\n",
       " 'closer': 0.0,\n",
       " 'closes': 0.0,\n",
       " 'closing': 0.0,\n",
       " 'closure': 0.0,\n",
       " 'closures': 0.0,\n",
       " 'clothing': 0.0,\n",
       " 'cloud': 0.0,\n",
       " 'coated': 0.0,\n",
       " 'coincident': 0.0,\n",
       " 'cold': 0.0,\n",
       " 'collective': 0.0,\n",
       " 'combination': 0.0,\n",
       " 'combined': 0.0,\n",
       " 'come': 0.0,\n",
       " 'comes': 0.0,\n",
       " 'comfort': 0.0,\n",
       " 'comibinations': 0.0,\n",
       " 'coming': 0.0,\n",
       " 'comments': 0.0,\n",
       " 'commercial': 0.0,\n",
       " 'commission': 0.0,\n",
       " 'commodities': 0.0,\n",
       " 'communicated': 0.0,\n",
       " 'communication': 0.0,\n",
       " 'communications': 0.0,\n",
       " 'companies': 0.0,\n",
       " 'companiesmeggitt': 0.0,\n",
       " 'company': 0.0,\n",
       " 'comparable': 0.0,\n",
       " 'comparatives': 0.0,\n",
       " 'compare': 0.0,\n",
       " 'compared': 0.0,\n",
       " 'compensation': 0.0,\n",
       " 'competition': 0.0,\n",
       " 'competitive': 0.0,\n",
       " 'completed': 0.0,\n",
       " 'complexity': 0.0,\n",
       " 'component': 0.0,\n",
       " 'componenta': 0.0,\n",
       " 'components': 0.0,\n",
       " 'composite': 0.0,\n",
       " 'composites': 0.0,\n",
       " 'comprising': 0.0,\n",
       " 'comptel': 0.0,\n",
       " 'concerning': 0.0,\n",
       " 'concerns': 0.0,\n",
       " 'conciliator': 0.0,\n",
       " 'concluded': 0.0,\n",
       " 'conditions': 0.0,\n",
       " 'confirmed': 0.0,\n",
       " 'congrats': 0.0,\n",
       " 'connect': 0.0,\n",
       " 'considerably': 0.0,\n",
       " 'considering': 0.0,\n",
       " 'consolidate': 0.0,\n",
       " 'consolidated': 0.0,\n",
       " 'construction': 0.0,\n",
       " 'consultancy': 0.0,\n",
       " 'consumer': 0.0,\n",
       " 'consumers': 0.0,\n",
       " 'consumption': 0.0,\n",
       " 'container': 0.0,\n",
       " 'contest': 0.0,\n",
       " 'continue': 0.0,\n",
       " 'continues': 0.0,\n",
       " 'continuing': 0.0,\n",
       " 'contract': 0.0,\n",
       " 'contracts': 0.0,\n",
       " 'contractual': 0.0,\n",
       " 'controlled': 0.0,\n",
       " 'cooperation': 0.0,\n",
       " 'copper': 0.0,\n",
       " 'coq': 0.0,\n",
       " 'corp': 0.0,\n",
       " 'corporation': 0.0,\n",
       " 'correleation': 0.0,\n",
       " 'correspond': 0.0,\n",
       " 'corresponding': 0.0,\n",
       " 'corresponds': 0.0,\n",
       " 'cost': 0.0,\n",
       " 'costco': 0.0,\n",
       " 'costs': 0.0,\n",
       " 'could': 0.0,\n",
       " 'counter': 0.0,\n",
       " 'countries': 0.0,\n",
       " 'country': 0.0,\n",
       " 'court': 0.0,\n",
       " 'courthouse': 0.0,\n",
       " 'cover': 0.0,\n",
       " 'covered': 0.0,\n",
       " 'cracking': 0.0,\n",
       " 'cramo': 0.0,\n",
       " 'creating': 0.0,\n",
       " 'credit': 0.0,\n",
       " 'crest': 0.0,\n",
       " 'crew': 0.0,\n",
       " 'crews': 0.0,\n",
       " 'crisis': 0.0,\n",
       " 'criticised': 0.0,\n",
       " 'criticising': 0.0,\n",
       " 'critics': 0.0,\n",
       " 'cruise': 0.0,\n",
       " 'crushed': 0.0,\n",
       " 'cry': 0.0,\n",
       " 'cs': 0.0,\n",
       " 'currency': 0.0,\n",
       " 'current': 0.0,\n",
       " 'currently': 0.0,\n",
       " 'customer': 0.0,\n",
       " 'customers': 0.0,\n",
       " 'cut': 0.0,\n",
       " 'cutlery': 0.0,\n",
       " 'cuts': 0.0,\n",
       " 'cutting': 0.0,\n",
       " 'cyber': 0.0,\n",
       " 'daily': 0.0,\n",
       " 'damage': 0.0,\n",
       " 'damaged': 0.0,\n",
       " 'danish': 0.0,\n",
       " 'dark': 0.0,\n",
       " 'data': 0.0,\n",
       " 'david': 0.0,\n",
       " 'day': 0.0,\n",
       " 'days': 0.0,\n",
       " 'deal': 0.0,\n",
       " 'dealers': 0.0,\n",
       " 'dealmakers': 0.0,\n",
       " 'debt': 0.0,\n",
       " 'decaliters': 0.0,\n",
       " 'december': 0.0,\n",
       " 'decent': 0.0,\n",
       " 'decided': 0.0,\n",
       " 'decision': 0.0,\n",
       " 'declare': 0.0,\n",
       " 'decline': 0.0,\n",
       " 'declined': 0.0,\n",
       " 'declining': 0.0,\n",
       " 'decrease': 0.0,\n",
       " 'decreased': 0.0,\n",
       " 'defect': 0.0,\n",
       " 'defends': 0.0,\n",
       " 'delay': 0.0,\n",
       " 'delayed': 0.0,\n",
       " 'delays': 0.0,\n",
       " 'delivery': 0.0,\n",
       " 'demand': 0.0,\n",
       " 'demanding': 0.0,\n",
       " 'denied': 0.0,\n",
       " 'dent': 0.0,\n",
       " 'depositary': 0.0,\n",
       " 'depressed': 0.0,\n",
       " 'deputy': 0.0,\n",
       " 'descending': 0.0,\n",
       " 'described': 0.0,\n",
       " 'design': 0.0,\n",
       " 'designs': 0.0,\n",
       " 'details': 0.0,\n",
       " 'determining': 0.0,\n",
       " 'deutsche': 0.0,\n",
       " 'devaluation': 0.0,\n",
       " 'developer': 0.0,\n",
       " 'device': 0.0,\n",
       " 'diabetes': 0.0,\n",
       " 'diageo': 0.0,\n",
       " 'diagnostic': 0.0,\n",
       " 'dialog': 0.0,\n",
       " 'did': 0.0,\n",
       " 'didn': 0.0,\n",
       " 'difficult': 0.0,\n",
       " 'digital': 0.0,\n",
       " 'diluted': 0.0,\n",
       " 'diminished': 0.0,\n",
       " 'dip': 0.0,\n",
       " 'dips': 0.0,\n",
       " 'director': 0.0,\n",
       " 'disagreement': 0.0,\n",
       " 'disappoint': 0.0,\n",
       " 'disappointing': 0.0,\n",
       " 'disappointment': 0.0,\n",
       " 'disappoints': 0.0,\n",
       " 'discounters': 0.0,\n",
       " 'disgraceful': 0.0,\n",
       " 'dismissed': 0.0,\n",
       " 'dismisses': 0.0,\n",
       " 'dispute': 0.0,\n",
       " 'distinctive': 0.0,\n",
       " 'distributable': 0.0,\n",
       " 'dive': 0.0,\n",
       " 'divest': 0.0,\n",
       " 'dividend': 0.0,\n",
       " 'division': 0.0,\n",
       " 'dma': 0.0,\n",
       " 'dnb': 0.0,\n",
       " 'dnf': 0.0,\n",
       " 'do': 0.0,\n",
       " 'dog': 0.0,\n",
       " 'dolce': 0.0,\n",
       " 'dollar': 0.0,\n",
       " 'dollars': 0.0,\n",
       " 'domestic': 0.0,\n",
       " 'dominance': 0.0,\n",
       " 'don': 0.0,\n",
       " 'donald': 0.0,\n",
       " 'doom': 0.0,\n",
       " 'double': 0.0,\n",
       " 'doubts': 0.0,\n",
       " 'down': 0.0,\n",
       " 'downgrade': 0.0,\n",
       " 'downgraded': 0.0,\n",
       " 'downgrades': 0.0,\n",
       " 'downside': 0.0,\n",
       " 'downward': 0.0,\n",
       " 'drillisch': 0.0,\n",
       " 'drop': 0.0,\n",
       " 'dropped': 0.0,\n",
       " 'dropping': 0.0,\n",
       " 'drops': 0.0,\n",
       " 'drought': 0.0,\n",
       " 'drug': 0.0,\n",
       " 'dt': 0.0,\n",
       " 'due': 0.0,\n",
       " 'duration': 0.0,\n",
       " 'during': 0.0,\n",
       " 'earlier': 0.0,\n",
       " 'early': 0.0,\n",
       " 'earnings': 0.0,\n",
       " 'ease': 0.0,\n",
       " 'easyjet': 0.0,\n",
       " 'eb': 0.0,\n",
       " 'ebit': 0.0,\n",
       " 'ebitda': 0.0,\n",
       " 'ecb': 0.0,\n",
       " 'economic': 0.0,\n",
       " 'economy': 0.0,\n",
       " 'edges': 0.0,\n",
       " 'eek': 0.0,\n",
       " 'effect': 0.0,\n",
       " 'effects': 0.0,\n",
       " 'efficiency': 0.0,\n",
       " 'efore': 0.0,\n",
       " 'eight': 0.0,\n",
       " 'elcoteq': 0.0,\n",
       " 'electricity': 0.0,\n",
       " 'electronic': 0.0,\n",
       " 'electronics': 0.0,\n",
       " 'elektrobit': 0.0,\n",
       " 'elevators': 0.0,\n",
       " 'elsevier': 0.0,\n",
       " 'embroiled': 0.0,\n",
       " 'employees': 0.0,\n",
       " 'employment': 0.0,\n",
       " 'employs': 0.0,\n",
       " 'emsa': 0.0,\n",
       " 'end': 0.0,\n",
       " 'ended': 0.0,\n",
       " 'ending': 0.0,\n",
       " 'energy': 0.0,\n",
       " 'engine': 0.0,\n",
       " 'engineering': 0.0,\n",
       " 'england': 0.0,\n",
       " 'engulfing': 0.0,\n",
       " 'enough': 0.0,\n",
       " 'enso': 0.0,\n",
       " 'entire': 0.0,\n",
       " 'environmental': 0.0,\n",
       " 'eps': 0.0,\n",
       " 'equipment': 0.0,\n",
       " 'equivalents': 0.0,\n",
       " 'er': 0.0,\n",
       " 'especially': 0.0,\n",
       " 'espn': 0.0,\n",
       " 'estate': 0.0,\n",
       " 'estimate': 0.0,\n",
       " 'estimated': 0.0,\n",
       " 'estimates': 0.0,\n",
       " 'estonia': 0.0,\n",
       " 'estonian': 0.0,\n",
       " 'eu': 0.0,\n",
       " 'eur': 0.0,\n",
       " 'euro': 0.0,\n",
       " 'euronext': 0.0,\n",
       " 'european': 0.0,\n",
       " 'euros': 0.0,\n",
       " 'even': 0.0,\n",
       " 'every': 0.0,\n",
       " 'everyone': 0.0,\n",
       " 'everything': 0.0,\n",
       " 'excess': 0.0,\n",
       " 'exchange': 0.0,\n",
       " 'excluding': 0.0,\n",
       " 'executive': 0.0,\n",
       " 'executives': 0.0,\n",
       " 'exel': 0.0,\n",
       " 'exits': 0.0,\n",
       " 'expectations': 0.0,\n",
       " 'expected': 0.0,\n",
       " 'expects': 0.0,\n",
       " 'expenditure': 0.0,\n",
       " 'expenditures': 0.0,\n",
       " 'expenses': 0.0,\n",
       " 'experience': 0.0,\n",
       " 'experiencing': 0.0,\n",
       " 'expires': 0.0,\n",
       " 'expiry': 0.0,\n",
       " 'explained': 0.0,\n",
       " 'explains': 0.0,\n",
       " 'export': 0.0,\n",
       " 'exports': 0.0,\n",
       " 'extending': 0.0,\n",
       " 'external': 0.0,\n",
       " 'extremely': 0.0,\n",
       " 'exxon': 0.0,\n",
       " 'exxonmobil': 0.0,\n",
       " 'facebook': 0.0,\n",
       " 'faces': 0.0,\n",
       " 'facing': 0.0,\n",
       " 'factor': 0.0,\n",
       " 'factory': 0.0,\n",
       " 'fade': 0.0,\n",
       " 'failed': 0.0,\n",
       " 'failing': 0.0,\n",
       " 'fair': 0.0,\n",
       " 'fall': 0.0,\n",
       " 'fallen': 0.0,\n",
       " 'fallers': 0.0,\n",
       " 'falling': 0.0,\n",
       " 'falls': 0.0,\n",
       " 'false': 0.0,\n",
       " 'families': 0.0,\n",
       " 'far': 0.0,\n",
       " 'fast': 0.0,\n",
       " 'fastenal': 0.0,\n",
       " 'fastjet': 0.0,\n",
       " 'faulty': 0.0,\n",
       " 'fda': 0.0,\n",
       " 'fears': 0.0,\n",
       " 'feb': 0.0,\n",
       " 'february': 0.0,\n",
       " 'federal': 0.0,\n",
       " 'fell': 0.0,\n",
       " 'fennia': 0.0,\n",
       " 'ferries': 0.0,\n",
       " 'ferry': 0.0,\n",
       " 'festive': 0.0,\n",
       " 'few': 0.0,\n",
       " 'fewer': 0.0,\n",
       " 'fh': 0.0,\n",
       " 'figures': 0.0,\n",
       " 'files': 0.0,\n",
       " 'finally': 0.0,\n",
       " 'finance': 0.0,\n",
       " 'financial': 0.0,\n",
       " 'financially': 0.0,\n",
       " 'financing': 0.0,\n",
       " 'find': 0.0,\n",
       " 'finds': 0.0,\n",
       " 'fine': 0.0,\n",
       " 'fined': 0.0,\n",
       " 'finland': 0.0,\n",
       " 'finnair': 0.0,\n",
       " 'finnish': 0.0,\n",
       " 'finnlines': 0.0,\n",
       " 'finton': 0.0,\n",
       " 'fireplace': 0.0,\n",
       " 'firms': 0.0,\n",
       " 'first': 0.0,\n",
       " 'fisas': 0.0,\n",
       " 'fiscal': 0.0,\n",
       " 'fiskars': 0.0,\n",
       " 'fitch': 0.0,\n",
       " 'five': 0.0,\n",
       " 'fixed': 0.0,\n",
       " 'flew': 0.0,\n",
       " 'flexible': 0.0,\n",
       " 'flights': 0.0,\n",
       " 'float': 0.0,\n",
       " 'floor': 0.0,\n",
       " 'floral': 0.0,\n",
       " 'flow': 0.0,\n",
       " 'flsmidth': 0.0,\n",
       " 'fluctuated': 0.0,\n",
       " 'fluctuation': 0.0,\n",
       " 'folded': 0.0,\n",
       " 'follow': 0.0,\n",
       " 'following': 0.0,\n",
       " 'food': 0.0,\n",
       " 'for': 0.0,\n",
       " 'force': 0.0,\n",
       " 'forced': 0.0,\n",
       " 'forecast': 0.0,\n",
       " 'forest': 0.0,\n",
       " 'forestry': 0.0,\n",
       " 'forex': 0.0,\n",
       " 'forssa': 0.0,\n",
       " 'foul': 0.0,\n",
       " 'found': 0.0,\n",
       " 'founder': 0.0,\n",
       " 'fourth': 0.0,\n",
       " 'fragile': 0.0,\n",
       " 'france': 0.0,\n",
       " 'franchising': 0.0,\n",
       " 'frankfurt': 0.0,\n",
       " 'freenet': 0.0,\n",
       " 'frequency': 0.0,\n",
       " 'fresh': 0.0,\n",
       " 'friday': 0.0,\n",
       " 'from': 0.0,\n",
       " 'frost': 0.0,\n",
       " 'ftse': 0.0,\n",
       " 'full': 0.0,\n",
       " 'fund': 0.0,\n",
       " 'fundementals': 0.0,\n",
       " 'funds': 0.0,\n",
       " 'furnaces': 0.0,\n",
       " 'furniture': 0.0,\n",
       " 'further': 0.0,\n",
       " 'furthermore': 0.0,\n",
       " 'future': 0.0,\n",
       " 'gabbana': 0.0,\n",
       " 'gain': 0.0,\n",
       " 'gains': 0.0,\n",
       " 'gallerix': 0.0,\n",
       " 'gap': 0.0,\n",
       " 'gas': 0.0,\n",
       " 'gave': 0.0,\n",
       " 'general': 0.0,\n",
       " 'generally': 0.0,\n",
       " 'generated': 0.0,\n",
       " 'geosentric': 0.0,\n",
       " 'germany': 0.0,\n",
       " 'get': 0.0,\n",
       " 'gettin': 0.0,\n",
       " 'getting': 0.0,\n",
       " 'gift': 0.0,\n",
       " 'gilead': 0.0,\n",
       " 'given': 0.0,\n",
       " 'glass': 0.0,\n",
       " 'glaston': 0.0,\n",
       " 'glaxosmithkline': 0.0,\n",
       " 'glencore': 0.0,\n",
       " 'glisten': 0.0,\n",
       " 'global': 0.0,\n",
       " 'glut': 0.0,\n",
       " 'go': 0.0,\n",
       " 'goes': 0.0,\n",
       " 'going': 0.0,\n",
       " 'goldman': 0.0,\n",
       " 'gone': 0.0,\n",
       " 'good': 0.0,\n",
       " 'goods': 0.0,\n",
       " 'got': 0.0,\n",
       " 'gotta': 0.0,\n",
       " 'grade': 0.0,\n",
       " 'grappling': 0.0,\n",
       " 'green': 0.0,\n",
       " 'grimaldi': 0.0,\n",
       " 'grocer': 0.0,\n",
       " 'grodno': 0.0,\n",
       " 'ground': 0.0,\n",
       " 'grounds': 0.0,\n",
       " 'group': 0.0,\n",
       " 'grow': 0.0,\n",
       " 'growhow': 0.0,\n",
       " 'growth': 0.0,\n",
       " 'guess': 0.0,\n",
       " 'guidance': 0.0,\n",
       " 'gundlach': 0.0,\n",
       " 'had': 0.0,\n",
       " 'half': 0.0,\n",
       " 'hall': 0.0,\n",
       " 'halted': 0.0,\n",
       " 'halved': 0.0,\n",
       " 'hampshire': 0.0,\n",
       " 'hand': 0.0,\n",
       " 'handle': 0.0,\n",
       " 'handling': 0.0,\n",
       " 'handset': 0.0,\n",
       " 'hanging': 0.0,\n",
       " 'happens': 0.0,\n",
       " 'hard': 0.0,\n",
       " 'hardest': 0.0,\n",
       " 'hardware': 0.0,\n",
       " 'harrison': 0.0,\n",
       " 'has': 0.0,\n",
       " 'hasten': 0.0,\n",
       " 'have': 0.0,\n",
       " 'havent': 0.0,\n",
       " 'hbos': 0.0,\n",
       " 'he': 0.0,\n",
       " 'head': 0.0,\n",
       " 'headcount': 0.0,\n",
       " 'headed': 0.0,\n",
       " 'heading': 0.0,\n",
       " 'heads': 0.0,\n",
       " 'heard': 0.0,\n",
       " 'heart': 0.0,\n",
       " 'heating': 0.0,\n",
       " 'hedge': 0.0,\n",
       " 'heed': 0.0,\n",
       " 'hel': 0.0,\n",
       " 'held': 0.0,\n",
       " 'helsinki': 0.0,\n",
       " 'hence': 0.0,\n",
       " 'here': 0.0,\n",
       " 'hhhmm': 0.0,\n",
       " 'high': 0.0,\n",
       " 'higher': 0.0,\n",
       " 'highs': 0.0,\n",
       " 'hikes': 0.0,\n",
       " 'him': 0.0,\n",
       " 'hires': 0.0,\n",
       " 'hit': 0.0,\n",
       " 'hits': 0.0,\n",
       " 'hitting': 0.0,\n",
       " 'hk': 0.0,\n",
       " 'hkscan': 0.0,\n",
       " 'hobby': 0.0,\n",
       " 'hold': 0.0,\n",
       " 'holdings': 0.0,\n",
       " 'hollola': 0.0,\n",
       " 'holy': 0.0,\n",
       " 'home': 0.0,\n",
       " 'homebuilders': 0.0,\n",
       " 'hope': 0.0,\n",
       " 'hopefully': 0.0,\n",
       " 'hopes': 0.0,\n",
       " 'horizon': 0.0,\n",
       " 'horizontal': 0.0,\n",
       " 'horrible': 0.0,\n",
       " 'hotels': 0.0,\n",
       " 'house': 0.0,\n",
       " 'households': 0.0,\n",
       " 'hover': 0.0,\n",
       " 'how': 0.0,\n",
       " 'however': 0.0,\n",
       " 'hsbc': 0.0,\n",
       " 'hss': 0.0,\n",
       " 'huhtamaki': 0.0,\n",
       " 'hungary': 0.0,\n",
       " 'hurt': 0.0,\n",
       " 'hurting': 0.0,\n",
       " 'ice': 0.0,\n",
       " 'icy': 0.0,\n",
       " 'if': 0.0,\n",
       " 'ignore': 0.0,\n",
       " 'ignored': 0.0,\n",
       " 'impact': 0.0,\n",
       " 'impacted': 0.0,\n",
       " 'impacts': 0.0,\n",
       " 'implement': 0.0,\n",
       " 'implementation': 0.0,\n",
       " 'implemented': 0.0,\n",
       " 'implementing': 0.0,\n",
       " 'imported': 0.0,\n",
       " 'imports': 0.0,\n",
       " 'impressive': 0.0,\n",
       " 'improvement': 0.0,\n",
       " 'imputed': 0.0,\n",
       " 'in': 0.0,\n",
       " 'inc': 0.0,\n",
       " 'incap': 0.0,\n",
       " 'included': 0.0,\n",
       " 'including': 0.0,\n",
       " 'income': 0.0,\n",
       " 'increased': 0.0,\n",
       " 'increases': 0.0,\n",
       " 'increasing': 0.0,\n",
       " 'increasingly': 0.0,\n",
       " 'incur': 0.0,\n",
       " 'incurred': 0.0,\n",
       " 'index': 0.0,\n",
       " 'india': 0.0,\n",
       " 'indicated': 0.0,\n",
       " 'indicating': 0.0,\n",
       " 'indicator': 0.0,\n",
       " 'industrial': 0.0,\n",
       " 'industry': 0.0,\n",
       " 'infection': 0.0,\n",
       " 'information': 0.0,\n",
       " 'informed': 0.0,\n",
       " 'ing': 0.0,\n",
       " 'initially': 0.0,\n",
       " 'initiated': 0.0,\n",
       " 'insiders': 0.0,\n",
       " 'instrument': 0.0,\n",
       " 'instruments': 0.0,\n",
       " 'insurance': 0.0,\n",
       " 'insurer': 0.0,\n",
       " 'intercontinental': 0.0,\n",
       " 'interest': 0.0,\n",
       " 'interim': 0.0,\n",
       " 'internals': 0.0,\n",
       " 'international': 0.0,\n",
       " 'internet': 0.0,\n",
       " 'interrupted': 0.0,\n",
       " 'intertek': 0.0,\n",
       " 'into': 0.0,\n",
       " 'intraday': 0.0,\n",
       " 'introduction': 0.0,\n",
       " 'invalid': 0.0,\n",
       " 'invested': 0.0,\n",
       " 'investigate': 0.0,\n",
       " 'investigation': 0.0,\n",
       " 'investment': 0.0,\n",
       " 'investments': 0.0,\n",
       " 'investor': 0.0,\n",
       " 'investors': 0.0,\n",
       " 'involved': 0.0,\n",
       " 'involving': 0.0,\n",
       " 'ipad': 0.0,\n",
       " 'iphone': 0.0,\n",
       " 'ipo': 0.0,\n",
       " 'irish': 0.0,\n",
       " 'irregularities': 0.0,\n",
       " 'is': 0.0,\n",
       " 'islands': 0.0,\n",
       " 'isn': 0.0,\n",
       " 'isrg': 0.0,\n",
       " 'issue': 0.0,\n",
       " 'issued': 0.0,\n",
       " 'issues': 0.0,\n",
       " 'it': 0.0,\n",
       " 'italy': 0.0,\n",
       " 'items': 0.0,\n",
       " 'its': 0.0,\n",
       " 'iwm': 0.0,\n",
       " 'jan': 0.0,\n",
       " 'january': 0.0,\n",
       " 'japan': 0.0,\n",
       " 'jefferies': 0.0,\n",
       " 'jeopardy': 0.0,\n",
       " 'job': 0.0,\n",
       " 'jobs': 0.0,\n",
       " 'jouko': 0.0,\n",
       " 'jp': 0.0,\n",
       " 'judge': 0.0,\n",
       " 'juhani': 0.0,\n",
       " 'jul': 0.0,\n",
       " 'july': 0.0,\n",
       " 'jump': 0.0,\n",
       " 'june': 0.0,\n",
       " 'juniper': 0.0,\n",
       " 'juri': 0.0,\n",
       " 'jury': 0.0,\n",
       " 'just': 0.0,\n",
       " 'jyvaskyla': 0.0,\n",
       " 'kallasvuo': 0.0,\n",
       " 'kaman': 0.0,\n",
       " 'kantar': 0.0,\n",
       " 'kapthing': 0.0,\n",
       " 'karvinen': 0.0,\n",
       " 'kauhava': 0.0,\n",
       " 'kauppalehti': 0.0,\n",
       " 'kaupthing': 0.0,\n",
       " 'kemira': 0.0,\n",
       " 'kept': 0.0,\n",
       " 'kesbv': 0.0,\n",
       " 'kesko': 0.0,\n",
       " 'key': 0.0,\n",
       " 'keywords': 0.0,\n",
       " 'kilometres': 0.0,\n",
       " 'kim': 0.0,\n",
       " 'kingfisher': 0.0,\n",
       " 'kiosk': 0.0,\n",
       " 'know': 0.0,\n",
       " 'knows': 0.0,\n",
       " 'kone': 0.0,\n",
       " 'konecranes': 0.0,\n",
       " 'krippl': 0.0,\n",
       " 'kronor': 0.0,\n",
       " 'kroons': 0.0,\n",
       " 'kyro': 0.0,\n",
       " 'laboratory': 0.0,\n",
       " 'lack': 0.0,\n",
       " 'lags': 0.0,\n",
       " 'laid': 0.0,\n",
       " 'lakshmi': 0.0,\n",
       " 'large': 0.0,\n",
       " 'larger': 0.0,\n",
       " 'largest': 0.0,\n",
       " 'lassila': 0.0,\n",
       " 'last': 0.0,\n",
       " 'latch': 0.0,\n",
       " 'latvia': 0.0,\n",
       " 'latvian': 0.0,\n",
       " 'law': 0.0,\n",
       " 'lawsuit': 0.0,\n",
       " 'lay': 0.0,\n",
       " 'laying': 0.0,\n",
       " 'layoffs': 0.0,\n",
       " 'le': 0.0,\n",
       " 'lead': 0.0,\n",
       " 'leader': 0.0,\n",
       " 'leads': 0.0,\n",
       " 'leak': 0.0,\n",
       " 'learning': 0.0,\n",
       " 'leased': 0.0,\n",
       " ...}"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27852b5b",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Do you need to make any changes to Sentence to make it more digestible for your model? Will you make any restrictions to your sample? Even if you dont choose to make any changes to the data, please describe your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbffc0",
   "metadata": {},
   "source": [
    "We want to map the sentences to a specific stock, market, or even country. We'll be attempting to create a category that contains information on the `subject` of the sentence.\n",
    "\n",
    "To do this, we will use spacy's token labels to identify proper nouns or subjects of each sentence.\n",
    "\n",
    "**Note: We weren't able to incorporate this in our model, but we believe this feature would help us address the prompt in the future.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "17bb0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject(sent):\n",
    "    '''\n",
    "    Tokenizes and identifies the subject of the sentence using spacy's English pipeline.\n",
    "    '''\n",
    "    doc=nlp(sent)\n",
    "    sub_toks = [tok for tok in doc if (tok.dep_ == \"nsubj\" or tok.pos_ == \"PROPN\")]\n",
    "    return sub_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f6ebb508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>Investments in product development stood at 6....</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>HSBC Says Unit to Book $585 Million Charge on ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4382 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment\n",
       "0     According to the Finnish-Russian Chamber of Co...   neutral\n",
       "1     The Swedish buyout firm has sold its remaining...   neutral\n",
       "2       $SPY wouldn't be surprised to see a green close  positive\n",
       "3     Shell's $70 Billion BG Deal Meets Shareholder ...  negative\n",
       "4     SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...  negative\n",
       "...                                                 ...       ...\n",
       "4377  Investments in product development stood at 6....   neutral\n",
       "4378  HSBC Says Unit to Book $585 Million Charge on ...  negative\n",
       "4379  RISING costs have forced packaging producer Hu...  negative\n",
       "4380  In the building and home improvement trade , s...   neutral\n",
       "4381  HELSINKI AFX - KCI Konecranes said it has won ...  positive\n",
       "\n",
       "[4382 rows x 2 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_subject = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bba01560",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_subject['Subject'] = with_subject['Sentence'].apply(get_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "54b40274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[Chamber, Commerce, companies, Finland, Russia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[firm, Finland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "      <td>positive</td>\n",
       "      <td>[SPY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[Shell, BG, Shareholder, Skepticism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[SSH, COMMUNICATIONS, SECURITY, CORP, STOCK, E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>Investments in product development stood at 6....</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[Investments]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>HSBC Says Unit to Book $585 Million Charge on ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[HSBC, Unit, Book]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[RISING, costs, Huhtamaki, Hampshire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[sales, EUR, mn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[HELSINKI, AFX, KCI, Konecranes, it, Bhushan, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4382 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment  \\\n",
       "0     According to the Finnish-Russian Chamber of Co...   neutral   \n",
       "1     The Swedish buyout firm has sold its remaining...   neutral   \n",
       "2       $SPY wouldn't be surprised to see a green close  positive   \n",
       "3     Shell's $70 Billion BG Deal Meets Shareholder ...  negative   \n",
       "4     SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...  negative   \n",
       "...                                                 ...       ...   \n",
       "4377  Investments in product development stood at 6....   neutral   \n",
       "4378  HSBC Says Unit to Book $585 Million Charge on ...  negative   \n",
       "4379  RISING costs have forced packaging producer Hu...  negative   \n",
       "4380  In the building and home improvement trade , s...   neutral   \n",
       "4381  HELSINKI AFX - KCI Konecranes said it has won ...  positive   \n",
       "\n",
       "                                                Subject  \n",
       "0       [Chamber, Commerce, companies, Finland, Russia]  \n",
       "1                                       [firm, Finland]  \n",
       "2                                                 [SPY]  \n",
       "3                  [Shell, BG, Shareholder, Skepticism]  \n",
       "4     [SSH, COMMUNICATIONS, SECURITY, CORP, STOCK, E...  \n",
       "...                                                 ...  \n",
       "4377                                      [Investments]  \n",
       "4378                                 [HSBC, Unit, Book]  \n",
       "4379              [RISING, costs, Huhtamaki, Hampshire]  \n",
       "4380                                   [sales, EUR, mn]  \n",
       "4381  [HELSINKI, AFX, KCI, Konecranes, it, Bhushan, ...  \n",
       "\n",
       "[4382 rows x 3 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_subject.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dbe6ea",
   "metadata": {},
   "source": [
    "Now, we want to clean `Sentences` in a way that enables accurate tokenization. To do this, we use Spacy, string, and Natural Language Toolkit tokenize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "2ed8863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "undesired = string.punctuation.replace('-', '')\n",
    "def punc_clean(text):\n",
    "    a=[w for w in text if w not in undesired]\n",
    "    return ''.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "485b5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stopword = nltk.corpus.stopwords.words('english')\n",
    "    stopword.remove('not')\n",
    "    a=[w for w in nltk.word_tokenize(text) if w not in stopword]\n",
    "    return ' '.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "df6e489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "f57ab9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset['Sentence'] = cleaned_dataset['Sentence'].apply(punc_clean)\n",
    "cleaned_dataset['Sentence'] = cleaned_dataset['Sentence'].apply(remove_stopwords).str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470797c3",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "Create a NLP model that uses the Sentence as an input, using Sentiment  as labels. Ideally, you will compare the results of several different models to find the optimal choice. What led you to choose your final model? Did you run into any roadblocks? Please describe your process in depth. Make sure to train your model on the training set only.\n",
    "\n",
    "The process we are using to build the model involves setting a baseline model using a quick and easy approach of preprocessing the data in a way that improves tokenization of the sentences. To do this, we used the Natural Language Toolkit package to clean and tokenize the `Sentence` data. Then, we used Scikit-Learn's TF-IDF Vectorizer to transform the `Sentence` data into a sparse matrix with dimensions matching the overall vocab count. After this, a simple Logistic Regression classifier is run on the data to perform multi-class classification for the three "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9da8eb",
   "metadata": {},
   "source": [
    "## NLTK and Scikit-Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "7a13effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(cleaned_dataset['Sentence'], cleaned_dataset['Sentiment'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "71443ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer(ngram_range=(1,2),min_df=1) # TODO: ADJUST PARAMS\n",
    "vector.fit(x_train)\n",
    "vect_X = vector.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "d1629d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_x_test = vector.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "5105845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "clf = model.fit(vect_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "efe6f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(vect_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "9def6fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6788321167883211, f1_score: 0.515463002636719\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(preds, y_test)\n",
    "f1_score = f1_score(preds, y_test, average='macro')\n",
    "\n",
    "print(f'accuracy: {accuracy}, f1_score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14baded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09647b05",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "2daa788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "30e4de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset['Sentence'] = tf_dataset['Sentence'].apply(punc_clean)\n",
    "tf_dataset['Sentence'] = tf_dataset['Sentence'].apply(remove_stopwords).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "e243f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tf_dataset['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "15e90eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4382, 48)"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(tf_dataset['Sentence'])\n",
    "\n",
    "# pad to same length\n",
    "X = pad_sequences(X, maxlen=pd.Series(X).apply(len).max())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "346ce075",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf_dataset['Sentiment'].replace(['negative', 'neutral', 'positive'],\n",
    "                        [0, 1, 2]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "eba22e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "59f686a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = tf_dataset['Sentence'].apply(len).max()\n",
    "emb_dim = 250\n",
    "cell_dim = 128\n",
    "num_classes = 3\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "penalty = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e91dcf",
   "metadata": {},
   "source": [
    "### LSTM layers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "fbbd1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class save_weights(keras.callbacks.Callback):\n",
    "    \"\"\"Callback to save weights that maximize test accuracy\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(save_weights, self).__init__()\n",
    "        \n",
    "        self.test_accuracy = []\n",
    "        \n",
    "        self.best = {\"Weights\": None, \"acc\": float(\"-inf\")}\n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        \n",
    "        # evaluate model loss and accuracy and update best based on evaluation\n",
    "        loss, acc = self.model.evaluate(x_test, y_test, verbose=False)\n",
    "        \n",
    "        if acc > self.best[\"acc\"]:\n",
    "            self.best[\"Weights\"] = self.model.get_weights()\n",
    "            self.best[\"acc\"] = acc\n",
    "            \n",
    "        self.test_accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "073404b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "54cd3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_builder(hp):\n",
    "    l2 = keras.regularizers.l2(penalty)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, emb_dim))\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    hp_dropout = hp.Choice('dropout', values=[0.1, 0.2, 0.3])\n",
    "    hp_re_dropout = hp.Choice('recurrent_dropout', values=[0.1, 0.2, 0.3])\n",
    "    \n",
    "    model.add(LSTM(cell_dim, return_sequences=True, dropout=hp_dropout, recurrent_dropout=hp_re_dropout))\n",
    "    model.add(LSTM(cell_dim))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\", kernel_regularizer=l2)) # try relu?\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "15c7ed1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project lstm\\DataHacks2022_tuning\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "lstm_tuner = kt.Hyperband(lstm_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='lstm',\n",
    "                     project_name='DataHacks2022_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "b6fddb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "b49fc630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 00m 45s]\n",
      "val_accuracy: 0.6261398196220398\n",
      "\n",
      "Best val_accuracy So Far: 0.6352583765983582\n",
      "Total elapsed time: 00h 06m 48s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "lstm_tuner.search(x_train, y_train, epochs=20, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = lstm_tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "2ad7da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_builder(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "8cbbf061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "b475b7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "52/52 [==============================] - 44s 780ms/step - loss: 1.0052 - accuracy: 0.5435\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 40s 764ms/step - loss: 0.6823 - accuracy: 0.7383\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 40s 774ms/step - loss: 0.3441 - accuracy: 0.8694\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 40s 772ms/step - loss: 0.2053 - accuracy: 0.9157\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 41s 781ms/step - loss: 0.1593 - accuracy: 0.9324\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 40s 780ms/step - loss: 0.1418 - accuracy: 0.9364\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 41s 789ms/step - loss: 0.1244 - accuracy: 0.9385\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 40s 772ms/step - loss: 0.1145 - accuracy: 0.9443\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 41s 783ms/step - loss: 0.1151 - accuracy: 0.9428\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 40s 773ms/step - loss: 0.1189 - accuracy: 0.9413\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 40s 766ms/step - loss: 0.1068 - accuracy: 0.9434\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 40s 764ms/step - loss: 0.1011 - accuracy: 0.9434\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 40s 761ms/step - loss: 0.0970 - accuracy: 0.9419\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 41s 783ms/step - loss: 0.0950 - accuracy: 0.9486\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 41s 791ms/step - loss: 0.0981 - accuracy: 0.9440\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 40s 772ms/step - loss: 0.0959 - accuracy: 0.9434\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 40s 772ms/step - loss: 0.0980 - accuracy: 0.9410\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 40s 776ms/step - loss: 0.0987 - accuracy: 0.9404\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 40s 776ms/step - loss: 0.1075 - accuracy: 0.9437\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 40s 771ms/step - loss: 0.0993 - accuracy: 0.9477\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, batch_size=64, callbacks=[save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "b39d7a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weights after full training:\n",
      "35/35 [==============================] - 3s 85ms/step - loss: 1.0870 - accuracy: 0.5255\n",
      "Using best weights from tf2.0 callback:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer sequential_1 weight shape (128, 384) is not compatible with provided weight shape (128, 512).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18176/3654080306.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Using best weights from tf2.0 callback:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Weights\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1862\u001b[0m         \u001b[0mref_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1864\u001b[1;33m           raise ValueError(\n\u001b[0m\u001b[0;32m   1865\u001b[0m               \u001b[1;34mf'Layer {self.name} weight shape {ref_shape} '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m               \u001b[1;34m'is not compatible with provided weight '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer sequential_1 weight shape (128, 384) is not compatible with provided weight shape (128, 512)."
     ]
    }
   ],
   "source": [
    "print(\"Using weights after full training:\")\n",
    "model.evaluate(x_test, y_test)\n",
    "print(\"Using best weights from tf2.0 callback:\")\n",
    "model.set_weights(save.best[\"Weights\"])\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "3cf710ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/Cast' defined at (most recent call last):\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ericw\\AppData\\Local\\Temp/ipykernel_18176/1543604611.py\", line 1, in <module>\n      model.predict(test_data)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 571, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 671, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential_1/Cast'\nCast string to float is not supported\n\t [[{{node sequential_1/Cast}}]] [Op:__inference_predict_function_820759]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18176/1543604611.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/Cast' defined at (most recent call last):\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ericw\\AppData\\Local\\Temp/ipykernel_18176/1543604611.py\", line 1, in <module>\n      model.predict(test_data)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 571, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"C:\\Users\\ericw\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 671, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential_1/Cast'\nCast string to float is not supported\n\t [[{{node sequential_1/Cast}}]] [Op:__inference_predict_function_820759]"
     ]
    }
   ],
   "source": [
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4ca63",
   "metadata": {},
   "source": [
    "### GRU layers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "2117645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "fc16bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_builder(hp):\n",
    "    l2 = keras.regularizers.l2(penalty)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, emb_dim))\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    hp_dropout = hp.Choice('dropout', values=[0.1, 0.2, 0.3])\n",
    "    hp_re_dropout = hp.Choice('recurrent_dropout', values=[0.1, 0.2, 0.3])\n",
    "    \n",
    "    # Tune the activation function\n",
    "    hp_activation = hp.Choice('activation', values=['tanh', 'relu'])\n",
    "    \n",
    "    model.add(GRU(cell_dim, activation=hp_activation, return_sequences=True, dropout=hp_dropout, recurrent_dropout=hp_re_dropout))\n",
    "    model.add(GRU(cell_dim, activation=hp_activation, dropout=hp_dropout, recurrent_dropout=hp_re_dropout))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\", kernel_regularizer=l2)) # try relu?\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "436815a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_tuner = kt.Hyperband(gru_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='gru',\n",
    "                     project_name='DataHacks2022_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "0872dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "79e5d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 Complete [00h 01m 58s]\n",
      "val_accuracy: 0.6337385773658752\n",
      "\n",
      "Best val_accuracy So Far: 0.6413373947143555\n",
      "Total elapsed time: 00h 32m 07s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "gru_tuner.search(x_train, y_train, epochs=20, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = gru_tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "8ed4705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gru_builder(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "23774763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "17eba9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "52/52 [==============================] - 42s 732ms/step - loss: 1.0004 - accuracy: 0.5484\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 38s 738ms/step - loss: 0.6291 - accuracy: 0.7459\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 37s 711ms/step - loss: 0.2837 - accuracy: 0.8965\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 37s 707ms/step - loss: 0.1712 - accuracy: 0.9257\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 38s 729ms/step - loss: 0.1501 - accuracy: 0.9267\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 37s 715ms/step - loss: 0.1271 - accuracy: 0.9318\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 36s 693ms/step - loss: 0.1181 - accuracy: 0.9352\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 36s 693ms/step - loss: 0.1141 - accuracy: 0.9391\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 36s 700ms/step - loss: 0.1090 - accuracy: 0.9373\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 36s 694ms/step - loss: 0.1074 - accuracy: 0.9355\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 36s 698ms/step - loss: 0.0997 - accuracy: 0.9358\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 36s 699ms/step - loss: 0.0998 - accuracy: 0.9434\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 37s 704ms/step - loss: 0.0968 - accuracy: 0.9407\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 37s 706ms/step - loss: 0.0940 - accuracy: 0.9446\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 37s 705ms/step - loss: 0.0907 - accuracy: 0.9467\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 37s 703ms/step - loss: 0.0900 - accuracy: 0.9419\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 36s 699ms/step - loss: 0.0896 - accuracy: 0.9498\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 37s 707ms/step - loss: 0.0894 - accuracy: 0.9431\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 37s 711ms/step - loss: 0.1004 - accuracy: 0.9416\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 38s 729ms/step - loss: 0.0952 - accuracy: 0.9437\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, batch_size=64, callbacks=[save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "0a654da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weights after full training:\n",
      "35/35 [==============================] - 3s 81ms/step - loss: 1.7900 - accuracy: 0.6223\n",
      "Using best weights from tf2.0 callback:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer sequential_1 weight shape (250, 384) is not compatible with provided weight shape (250, 512).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18176/3654080306.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Using best weights from tf2.0 callback:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Weights\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1862\u001b[0m         \u001b[0mref_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1864\u001b[1;33m           raise ValueError(\n\u001b[0m\u001b[0;32m   1865\u001b[0m               \u001b[1;34mf'Layer {self.name} weight shape {ref_shape} '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m               \u001b[1;34m'is not compatible with provided weight '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer sequential_1 weight shape (250, 384) is not compatible with provided weight shape (250, 512)."
     ]
    }
   ],
   "source": [
    "print(\"Using weights after full training:\")\n",
    "model.evaluate(x_test, y_test)\n",
    "print(\"Using best weights from tf2.0 callback:\")\n",
    "model.set_weights(save.best[\"Weights\"])\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13270a5",
   "metadata": {},
   "source": [
    "### LSTM and GRU layers combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "b9ca85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_gru_builder(hp):\n",
    "    l2 = keras.regularizers.l2(penalty)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, emb_dim))\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    hp_dropout = hp.Choice('dropout', values=[0.1, 0.2, 0.3])\n",
    "    hp_re_dropout = hp.Choice('recurrent_dropout', values=[0.1, 0.2, 0.3])\n",
    "    \n",
    "    # Tune the activation function\n",
    "    hp_activation = hp.Choice('activation', values=['tanh', 'relu'])\n",
    "    \n",
    "    model.add(LSTM(cell_dim, return_sequences=True, dropout=hp_dropout, recurrent_dropout=hp_re_dropout))\n",
    "    model.add(GRU(cell_dim, activation=hp_activation, dropout=hp_dropout, recurrent_dropout=hp_re_dropout))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\", kernel_regularizer=l2))\n",
    "\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "397ad398",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_gru_save = save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "1464a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_gru_tuner = kt.Hyperband(lstm_gru_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='lstm_gru',\n",
    "                     project_name='DataHacks2022_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "09927045",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "eb6d57b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 01m 15s]\n",
      "val_accuracy: 0.6413373947143555\n",
      "\n",
      "Best val_accuracy So Far: 0.6413373947143555\n",
      "Total elapsed time: 00h 15m 47s\n",
      "\n",
      "Search: Running Trial #16\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.3               |0.3               |dropout\n",
      "0.1               |0.3               |recurrent_dropout\n",
      "tanh              |relu              |activation\n",
      "7                 |7                 |tuner/epochs\n",
      "3                 |3                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "1                 |1                 |tuner/round\n",
      "0009              |0007              |tuner/trial_id\n",
      "\n",
      "Epoch 4/7\n",
      "83/83 [==============================] - 22s 217ms/step - loss: 0.9688 - accuracy: 0.5681 - val_loss: 0.9192 - val_accuracy: 0.6125\n",
      "Epoch 5/7\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 0.6101 - accuracy: 0.7542 - val_loss: 0.9205 - val_accuracy: 0.5851\n",
      "Epoch 6/7\n",
      "18/83 [=====>........................] - ETA: 13s - loss: 0.3396 - accuracy: 0.8785"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18176/2817072960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlstm_gru_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Get the optimal hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbest_hps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_gru_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m             \u001b[1;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mobj_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         return tuner_utils.convert_to_metrics_dict(\n\u001b[0;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HyperModel.fit()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_gru_tuner.search(x_train, y_train, epochs=20, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = lstm_gru_tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "91a21799",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_gru_builder(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "6b86eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "0a0ecc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 6/52 [==>...........................] - ETA: 34s - loss: 1.1230 - accuracy: 0.4479"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18176/4023903436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, batch_size=64, callbacks=[save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "67b62e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weights after full training:\n",
      "35/35 [==============================] - 4s 86ms/step - loss: 1.0870 - accuracy: 0.5255\n",
      "Using best weights from tf2.0 callback:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18176/26924389.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Using best weights from tf2.0 callback:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_gru_save\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Weights\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1842\u001b[0m         \u001b[0mexpected_num_weights\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mexpected_num_weights\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1845\u001b[0m       raise ValueError(\n\u001b[0;32m   1846\u001b[0m           \u001b[1;34m'You called `set_weights(weights)` on layer \"%s\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "print(\"Using weights after full training:\")\n",
    "model.evaluate(x_test, y_test)\n",
    "print(\"Using best weights from tf2.0 callback:\")\n",
    "model.set_weights(lstm_gru_save.best[\"Weights\"])\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d5794",
   "metadata": {},
   "source": [
    "# Model Testing\n",
    "\n",
    "Please report the performance of your model on the training set. How does your model perform? Please report your accuracy and F1 score. Also, using the test set, please provide a CSV of your predicted values for Sentiment with your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "a7f24146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance was done up above in Model Building section since it was easier to adjust model parameters with it up there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "ecc86e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "192a1201",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test['Sentence'] = cleaned_test['Sentence'].apply(punc_clean)\n",
    "cleaned_test['Sentence'] = cleaned_test['Sentence'].apply(remove_stopwords).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "239f0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = vector.transform(cleaned_test['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "fe63cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = clf.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "e66c3d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(test_predictions).to_frame().to_csv('AdvancedTrack_BofaBros_predictions.csv', header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b305b2f",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://www.nasdaq.com/market-activity/stocks/screener"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
