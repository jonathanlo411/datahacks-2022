<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" type="image/svg+xml" href="data/favicon.svg">
    <link rel="icon" type="image/png" href="data/favicon.png">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <script defer src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script defer src="https://code.jquery.com/jquery-3.1.0.min.js"></script>
    <script defer src="app.js"></script>
    <title>Bofa Bros - DataHacks 2022</title>
</head>
<body>
    <h1 id="title">DataHacks 2022</h1>
    <div id="body-page">
    <div class="svg-wrapper">
        <svg id="visual" viewBox="0 0 1800 600" width="1800" height="600" preserveAspectRatio="none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1"><path d="M0 365L30 393.2C60 421.3 120 477.7 180 484.5C240 491.3 300 448.7 360 453.5C420 458.3 480 510.7 540 511.3C600 512 660 461 720 432.5C780 404 840 398 900 420.3C960 442.7 1020 493.3 1080 527.3C1140 561.3 1200 578.7 1260 578.2C1320 577.7 1380 559.3 1440 548C1500 536.7 1560 532.3 1620 518.2C1680 504 1740 480 1770 468L1800 456L1800 601L1770 601C1740 601 1680 601 1620 601C1560 601 1500 601 1440 601C1380 601 1320 601 1260 601C1200 601 1140 601 1080 601C1020 601 960 601 900 601C840 601 780 601 720 601C660 601 600 601 540 601C480 601 420 601 360 601C300 601 240 601 180 601C120 601 60 601 30 601L0 601Z" fill="#ffffff" stroke-linecap="round" stroke-linejoin="miter"></path></svg>
    </div>
    <div id="back-white">
    <div id="center">

        <!-- Team Section -->
        <div id="team">
            <h2 id="team-title">Team Bofa Bros</h2>
            <p id="team-desc">
                Returning for a second year after their honorable mention from Datahacks 2021, Team Wild Rifters, now renamed to Team Bofa Bros, composed of Jonathan Lo, Eric Wang, and Justin Liang, hope to build upon their previous experiences to showcase a development of knowledge in this year’s Datahacks 2022 Advanced Path. With a newfound appreciation for the ability of data to help change the understanding of the world around us, Team Bofa Bros hopes to use this hackathon as the backbone to create something much greater.

            </p>
            <div id="member-list">
                <div class="member" style="--animation-order: 1;" onclick="location.href = 'https://www.linkedin.com/in/jonathanlo411/'">
                    <div class="pfp-wrapper">
                        <img src="data/jlo.jpg">
                    </div>
                    <h4 class="member-name">Jonathan Lo</h4>
                    <h6 class="member-desc">Data Science</h6>
                </div>
                <div class="member" style="--animation-order: 2;" onclick="location.href = 'https://www.linkedin.com/in/eric3wang/'">
                    <div class="pfp-wrapper">
                        <img src="data/e3w.jpg">
                    </div>
                    <h4 class="member-name">Eric Wang</h4>
                    <h6 class="member-desc">Data Science</h6>
                </div>
                <div class="member" style="--animation-order: 3;" onclick="location.href = 'https://www.linkedin.com/in/justin-liang-146aa219a/'">
                    <div class="pfp-wrapper">
                        <img src="data/jli.png">
                    </div>
                    <h4 class="member-name">Justin Liang</h4>
                    <h6 class="member-desc">Biochemistry</h6>
                </div>
            </div>
        </div>
        
        <!-- Process Section -->
        <h2 id="process-title">Process</h2>
        <div id="process">
            <div class="step" id="sec0">
                <h3 class="heading">0. Introduction</h3>
                <p>In this project, we use a dataset consisting of financial statements and sentiments to make predictions about sentiment. We dove into the data and analyzed any potential trends. After our exploratory data analysis (EDA), we decided a {} neural network would be the best option for predictions. After testing parameters we made the decision to proceed with a {} based architecture.</p>
            </div>
            <div class="step" id="sec1">
                <h3 class="heading">1. Data Cleaning/Preprocessing</h3>
                <p>
                    The data consists of two columns. One composed of sentences and the other composed of the sentence’s sentiment. The sentence topics were focused around finance and the stock market. The data originates from a Kaggle dataset which originates from a study about good and bad debt. On initial data load, we noticed that some of the strings were already being processed very differently. We then realized that this was due to an issue with Pandas utilizing mathjax to preprocess data and fixed the issue.
                    <br><br>
                    We initially thought of taking a surface level approach and to try to uncover as many details as we could about sentences and sentence structure. However, Natural Language Processing is a very difficult process so we concluded that this approach would most likely end fruitless. We then decided that using pre-established methods were better and began analyzing word significance and distribution of sentiments. 
                    <br><br>
                    We then proceeded to tokenize the sentences which gave context to the sentences. This would allow the model to understand sentences in a better way due to the broken down nature. During this process, we needed to strip punctuation and remove capitalization. This would ensure that words with the same meanings would be tokenized similarly. In an extreme example:</p>
                    <pre><code>
>>> s1 = “That ain’t half bad.”
>>> s2 = “Bad halves make a good whole.”
>>> compare_structure(s1, s2)
False
                    </code></pre><p>
                    The above example is not entirely accurate but provides a general understanding of the potential issues of improper formats in tokenization. For more information, checkout DSC96, DSC80, or LIGN167!
                    </p>
            </div>
            <div class="step" id="sec2">
                <h3 class="heading">2. Visualizations</h3>
                <p>As seen from the distribution of sentiment, neutrality is very persistent through the training data. This might cause our model to produce predictions that are skewed to neutrality rather than positive or negative.</p>
                <pre><code>
# Loading Data
train_data = pd.read_csv('advanced_trainset.csv')

# Obtaining frequency/counts of each sentiment 
sentiment_counts = train_data['Sentiment'].value_counts().to_frame().reset_index()

# Plotting
fig = px.pie(sentiment_counts, values='Sentiment', names='index', title="Sentiment Distribution")
fig.show()
                </code></pre>
                <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://chart-studio.plotly.com/~jonathanlo411/1/#/" height="525" width="100%"></iframe>
                <p>In the sentence below, our model identifies the word “Finnish” as a National or Religious Political Group (NORP), as it is used to describe a group of people who identify as Finnish. Along with this the model also identifies the countries of “Russia” and “Finland” as GPE, or geological locations.</p>
                <pre><code>
html = displacy.render(doc, style="ent", page=True)
displacy.render(doc, style="ent")
                </code></pre>
                <div class="img-ps">
                    <img src="data/word-play.png">
                </div>
                <p>The model below shows the connection held between certain words found in the data. Words such as “Finnish-” and “Russian” are connected since they are both adjectives used to describe some noun that follows. Our model is similar to information priming as these words “prime” the mind/model to have an expectation of what words/phrases could follow.</p>
                <pre><code>
sent = train_data.loc[0]['Sentence']
doc=nlp(sent)
html = displacy.render(doc, style="dep", page=True)
                </code></pre>
                <div class="img-ps">
                    <img src="data/word.png">
                </div>
            </div>
            <div class="step" id="sec3">
                <h3 class="heading">3. Analysis/Results</h3>
                <p>After our visualizations and processed/tokenized data, we proceed with a recurrent neural network for NLP. Recurrent neural networks are advantageous because they retain a sort of memory which fits our prediction usage best.
                    <br><br>
                    Next, we had to decide between Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU).  LSTM is older than GRU so the technology is not as “advanced”. LSTM provides a more robust way to carry out the weighting process in a neural network. On the other hand GRU is younger and is being increasingly used. GRU is simpler than LSTM and as such, is faster on training and fitting the data. Performance is roughly on par with LSTM but some sources say otherwise. We decided to proceed with the {} architecture because we thought the {} best fit the needs in this situation.</p>
                    
                <div class="img-ws">
                    <img src="data/gru-d.jpg">
                </div><p>
                    Key parameters we tuned were dropout rate and activation functions. Dropout rate is the fraction of the units to drop for the linear transformation of the inputs. We utilize this along with the vectorized (and tokenized) sentence data to aim for the best prediction accuracy. We also cycled through different activation functions. We thought that ReLU and TanH functions were the best for sentimental analysis predictors.
                    </p>
                <div class="img-w">
                    <img src="data/gru.png">
                </div>
            </div>
            <div class="step" id="sec4">
                <h3 class="heading">4. Conclusion</h3>
                <p>During this Datahacks 2022, we learned a lot about Deep Learning in NLP. In the beginning, we first pruned out all of the poorly written sentences in order for the model to be able to process without there being issues with certain characters. We then moved on to create visualizations to get a better understanding of the relationships in the data and move forward accordingly. We then focused on building and training the model using the newly cleaned data set, where the model would first vectorize the words in a sentence using word embedding, and then used the information gathered to train. Our model was able to predict sentiments with high accuracy after feeding in the sentences. 
<br><br>
                    We already knew that working with teammates is more efficient and faster than working alone. However, during this hackathon, we learned that truly good teammates will push others and thus, themselves far above expectations. We completed a lot more than we expected considering experience level and we are truly satisfied with DataHacks 2022.
                    </p>
            </div>
            <div class="step" id="sec5">
                <h3 class="heading">5. Future Improvements</h3>
                <p>In our current model, we fell short on time when it came down to testing different neural network architectures and had to simply resort to using the model that produced the best results and took the least amount of time to run. 

                    In the future, we hope that we can further fine tune our model to more accurately predict the future market based on the sentiment today. Given that we were limited on time and on processing power, we hope that given the opportunity of being able to use a more powerful system, we could use the headroom to further expand our data set to capture a more accurate representation of the sentiment surrounding the economic landscape and market. 
                    </p>
            </div>
        </div>   

    </div>
    </div>

    <div id="footer-spacer"></div>
    <footer>
        <h5>2022 Bofa Bros, Inc.</h5>
    </footer>
    </div>

    <!-- Side Nav -->
    <div class="sidebar" id="side-nav">
        <div class="sidebar-content" id="int">
            <i class="material-icons">info</i>
            <h2>Introduction</h2>
        </div>
        <div class="sidebar-content" id="dat">
            <i class="material-icons">cleaning_services</i>
            <h2>Data Cleaning/Preprocessing</h2>
        </div>
        <div class="sidebar-content" id="vis">
            <i class="material-icons">assessment</i>
            <h2>Visualizations</h2>
        </div>
        <div class="sidebar-content" id="ana">
            <i class="material-icons">query_stats</i>
            <h2>Analysis/Results</h2>
        </div>
        <div class="sidebar-content" id="con">
            <i class="material-icons">sports_score</i>
            <h2>Conclusion</h2>
        </div>
        <div class="sidebar-content" id="fut">
            <i class="material-icons">update</i>
            <h2>Future Improvements</h2>
        </div>
    </div>
</body>
</html>